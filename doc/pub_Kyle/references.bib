%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Shiran Dudy at 2015-01-07 12:40:13 -0800 


%% Saved with string encoding Unicode (UTF-8) 



@article{graham1971phonological,
	Author = {Graham, Louella W and House, Arthur S},
	Date-Added = {2015-01-07 20:34:43 +0000},
	Date-Modified = {2015-01-07 20:34:43 +0000},
	Journal = {The Journal of the Acoustical Society of America},
	Number = {2B},
	Pages = {559--566},
	Publisher = {Acoustical Society of America},
	Title = {Phonological oppositions in children: A perceptual study},
	Volume = {49},
	Year = {1971},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QD0dyYWhhbS0xOTYwLnBkZtIXCxgZV05TLmRhdGFPEQGWAAAAAAGWAAIAAAJIRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADO80NASCsAAADbSBgPR3JhaGFtLTE5NjAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAZZjw9DSxQoAAAAAAAAAAAABAAIAAAkgAAAAAAAAAAAAAAAAAAAAA2xpdAAAEAAIAADO87PAAAAAEQAIAADQ0zWKAAAAAQAcANtIGADbSBIA20d7AAjZvAAI2bsACDaEAAJkZgACAEJIRDpVc2VyczoAZHVkeToAQ1NMVToAUHJvamVjdHM6AHNjb3Jpbmc6AGRvYzoAbGl0OgBHcmFoYW0tMTk2MC5wZGYADgAgAA8ARwByAGEAaABhAG0ALQAxADkANgAwAC4AcABkAGYADwAGAAIASABEABIAOFVzZXJzL2R1ZHkvQ1NMVS9Qcm9qZWN0cy9zY29yaW5nL2RvYy9saXQvR3JhaGFtLTE5NjAucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AoAClAK0CRwJJAk4CWQJiAnACdAJ7AoQCiQKWApkCqwKuArMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACtQ==}}

@inproceedings{shobaki2000ogi,
	Author = {Shobaki, Khaldoun and Hosom, John-Paul and Cole, Ronald},
	Booktitle = {Proc. of ICSLP},
	Date-Added = {2015-01-06 21:48:44 +0000},
	Date-Modified = {2015-01-06 21:48:44 +0000},
	Pages = {564--567},
	Title = {The OGI kids' speech corpus and recognizers},
	Year = {2000}}

@article{mcleod2002typical,
	Author = {McLeod, Sharynne},
	Date-Added = {2014-12-30 16:18:28 +0000},
	Date-Modified = {2014-12-30 16:18:28 +0000},
	Journal = {Retrieved January},
	Pages = {2008},
	Title = {Typical development of speech},
	Volume = {13},
	Year = {2002}}

@manual{Goldman-Fristoe2000,
	Author = {R. Goldman and M. Fristoe},
	Date-Added = {2014-12-15 19:04:06 +0000},
	Date-Modified = {2014-12-15 19:06:22 +0000},
	Title = {Goldman-Fristoe test of articulation-2},
	Year = {2000}}

@article{witt1997computer,
	Annote = {- non-native speech to aid computer assisted pronunciation teaching 
- ASR for recognition
- confidence measure indicates phoneme level and quality
- artificial vs non-native},
	Author = {Witt, Silke and Young, Steve},
	Date-Added = {2014-10-31 01:21:52 +0000},
	Date-Modified = {2014-12-30 10:31:56 +0000},
	Journal = {Language Teaching and Language Technology Groningen, The Netherlands},
	Title = {Computer-assisted pronunciation teaching based on automatic speech recognition},
	Year = {1997}}

@inproceedings{russell1996applications,
	Author = {Russell, Martin and Brown, Catherine and Skilling, Adrian and Series, Rob and Wallace, Julie and Bonham, Bill and Barker, Paul},
	Booktitle = {Spoken Language, 1996. ICSLP 96. Proceedings., Fourth International Conference on},
	Date-Added = {2014-10-31 01:20:00 +0000},
	Date-Modified = {2014-10-31 01:20:00 +0000},
	Organization = {IEEE},
	Pages = {176--179},
	Title = {Applications of automatic speech recognition to speech and language development in young children},
	Volume = {1},
	Year = {1996}}

@article{neri2002feedback,
	Author = {Neri, Ambra and Cucchiarini, Catia and Strik, Helmer},
	Date-Added = {2014-10-31 01:18:42 +0000},
	Date-Modified = {2014-10-31 01:18:42 +0000},
	Journal = {Proceedings of CALL professionals and the future of CALL research},
	Pages = {179--188},
	Title = {Feedback in computer assisted pronunciation training: When technology meets pedagogy},
	Year = {2002}}

@article{mostow1999giving,
	Author = {Mostow, Jack and others},
	Date-Added = {2014-10-31 01:17:19 +0000},
	Date-Modified = {2014-10-31 01:17:19 +0000},
	Journal = {CALICO journal},
	Number = {3},
	Pages = {407--424},
	Title = {Giving help and praise in a reading tutor with imperfect listening--because automated speech recognition means never being able to say you're certain},
	Volume = {16},
	Year = {1999}}

@article{menzel2000automatic,
	Author = {Menzel, Wolfgang and Herron, Daniel and Bonaventura, Patrizia and Morton, Rachel},
	Date-Added = {2014-10-31 01:15:28 +0000},
	Date-Modified = {2014-10-31 01:15:28 +0000},
	Journal = {Proceedings of INSTILL},
	Pages = {49--56},
	Title = {Automatic detection and correction of non-native English pronunciations},
	Year = {2000}}

@inproceedings{chen2007development,
	Author = {Chen, Yeou-Jiunn and Huang, Jing-Wei},
	Booktitle = {3rd Kuala Lumpur International Conference on Biomedical Engineering 2006},
	Date-Added = {2014-10-31 01:00:23 +0000},
	Date-Modified = {2014-10-31 01:00:23 +0000},
	Organization = {Springer},
	Pages = {637--639},
	Title = {Development of Articulation Training System with Speech Recognition Based Automatic Pronunciation Detection Mechanism},
	Year = {2007}}

@booklet{asha2008,
	Author = {Andrea Castrogiovanni},
	Date-Added = {2014-10-15 21:37:38 +0000},
	Date-Modified = {2014-10-15 21:40:50 +0000},
	Howpublished = {American Speech-Language Hearing Association},
	Title = {Incidence and Prevalence of Communication Disorders and Hearing Loss in Children},
	Year = {2008}}

@booklet{asha2006,
	Author = {Jeanette Janota},
	Date-Added = {2014-10-15 21:34:01 +0000},
	Date-Modified = {2014-10-15 21:40:46 +0000},
	Howpublished = {American Speech-Language Hearing Association},
	Title = {2006 Schools Survey Report: Caseload Characteristics},
	Year = {2006}}

@inproceedings{engwall2006,
	Author = {Engwall, O. and B{\"a}lter, O. and {\"O}ster, A.M. and Kjellstr{\"o}m, H},
	Booktitle = {Proceedings of CHI 2006},
	Date-Added = {2014-10-15 21:28:53 +0000},
	Date-Modified = {2014-10-15 21:29:47 +0000},
	Title = {Feedback Management in the Pronunciation Training System ARTUR},
	Year = {2006}}

@inproceedings{neri2002,
	Author = {Neri, A. and Cucchiarini, C. and Strik, H.},
	Booktitle = {Proceedings of CALL Professionals and the Future of CALL Research},
	Date-Added = {2014-10-15 21:26:25 +0000},
	Date-Modified = {2014-10-15 21:27:16 +0000},
	Title = {Feedback in Computer Assisted Pronunciation Training: When Technology Meets Pedagogy},
	Year = {2002}}

@article{koenig2001,
	Author = {Koenig, L. L.},
	Date-Added = {2014-10-15 21:24:32 +0000},
	Date-Modified = {2014-10-15 21:36:49 +0000},
	Journal = {Journal of Speech, Language, \& Hearing Research},
	Number = {5},
	Pages = {1058--10068},
	Title = {Distributional Characteristics of VOT in Children's Voiceless Aspirated Stops and Interpretation of Developmental Trends,},
	Volume = {44},
	Year = {2001}}

@inproceedings{antoniou2001,
	Author = {Antoniou, C},
	Booktitle = {Proceedings of the International Conference on Acoustics, Speech and Signal Processing},
	Date-Added = {2014-10-15 21:22:44 +0000},
	Date-Modified = {2014-10-15 21:24:00 +0000},
	Journal = {Proceedings of the International Conference on Acoustics, Speech and Signal Processing},
	Title = {Modular Neural Networks Exploit Large Acoustic Context Through Broad-Class Posteriors for Continuous Speech Recognition},
	Year = {2001}}

@article{gierut1998,
	Author = {Gierut, Judith A},
	Date-Added = {2014-10-15 00:30:27 +0000},
	Date-Modified = {2014-10-15 00:31:25 +0000},
	Journal = {Journal of Speech, Language, and Hearing Research},
	Pages = {S85--S100},
	Title = {Treatment Efficacy: Functional Phonological Disorders in Children},
	Volume = {41},
	Year = {1998}}

@article{bohn2012native,
	Author = {Bohn, Ocke-Schwen and Best, Catherine T},
	Date-Added = {2014-10-13 03:04:20 +0000},
	Date-Modified = {2014-10-13 03:04:20 +0000},
	Journal = {Journal of Phonetics},
	Number = {1},
	Pages = {109--128},
	Publisher = {Elsevier},
	Title = {Native-language phonetic and phonological influences on perception of American English approximants by Danish and German listeners},
	Volume = {40},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV1Cb2huLTIwMTIucGRm0hcLGBlXTlMuZGF0YU8RAY4AAAAAAY4AAgAAAkhEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAM7zQ0BIKwAAANtIGA1Cb2huLTIwMTIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA6tbq0GCO0AAAAAAAAAAAAAEAAgAACSAAAAAAAAAAAAAAAAAAAAADbGl0AAAQAAgAAM7zs8AAAAARAAgAANBg8UAAAAABABwA20gYANtIEgDbR3sACNm8AAjZuwAINoQAAmRmAAIAQEhEOlVzZXJzOgBkdWR5OgBDU0xVOgBQcm9qZWN0czoAc2NvcmluZzoAZG9jOgBsaXQ6AEJvaG4tMjAxMi5wZGYADgAcAA0AQgBvAGgAbgAtADIAMAAxADIALgBwAGQAZgAPAAYAAgBIAEQAEgA2VXNlcnMvZHVkeS9DU0xVL1Byb2plY3RzL3Njb3JpbmcvZG9jL2xpdC9Cb2huLTIwMTIucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AnAChAKkCOwI9AkICTQJWAmQCaAJvAngCfQKKAo0CnwKiAqcAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACqQ==}}

@inproceedings{mak2003plaser,
	Author = {Mak, Brian and Siu, Manhung and Ng, Mimi and Tam, Yik-Cheung and Chan, Yu-Chung and Chan, Kin-Wah and Leung, Ka-Yee and Ho, Simon and Chong, Fong-Ho and Wong, Jimmy and others},
	Booktitle = {Proceedings of the HLT-NAACL 03 workshop on Building educational applications using natural language processing-Volume 2},
	Date-Added = {2014-09-29 19:59:01 +0000},
	Date-Modified = {2014-09-29 19:59:01 +0000},
	Organization = {Association for Computational Linguistics},
	Pages = {23--29},
	Title = {PLASER: pronunciation learning via automatic speech recognition},
	Year = {2003}}

@inproceedings{sevenster1998evaluation,
	Author = {Sevenster, Bob and de Krom, Guus and Bloothooft, Gerrit},
	Booktitle = {Proc. STiLL},
	Date-Added = {2014-09-29 19:13:40 +0000},
	Date-Modified = {2014-09-29 19:13:40 +0000},
	Pages = {91--94},
	Title = {Evaluation and training of second-language learners' pronunciation using phoneme-based HMMs},
	Year = {1998}}

@inproceedings{menzel2000isle,
	Author = {Menzel, Wolfgang and Atwell, Eric and Bonaventura, Patrizia and Herron, Daniel and Howarth, Peter and Morton, Rachel and Souter, Clive},
	Booktitle = {LREC},
	Date-Added = {2014-09-29 19:09:55 +0000},
	Date-Modified = {2014-09-29 19:09:55 +0000},
	Organization = {Citeseer},
	Title = {The ISLE Corpus of Non-Native Spoken English.},
	Year = {2000}}

@inproceedings{Motsow1997,
	Author = {Mostow , Aist},
	Booktitle = {AAAI-97: Proceedings of the Fourteenth National Conference on Artificial Intelligence and The Ninth Annual Conference on Innovative Applications of Artificial Intelligence},
	Date-Added = {2014-09-29 18:59:14 +0000},
	Date-Modified = {2014-10-24 00:35:41 +0000},
	Organization = {Aaai Press},
	Pages = {355},
	Title = {The sounds of silence: towards automated evaluation of student learning in a reading tutor that listens},
	Volume = {14},
	Year = {1997}}

@article{eskenazi1999using,
	Author = {Eskenazi, Maxine},
	Date-Added = {2014-09-29 18:55:33 +0000},
	Date-Modified = {2014-09-29 18:55:33 +0000},
	Journal = {Language learning \& technology},
	Number = {2},
	Pages = {62--76},
	Title = {Using automatic speech processing for foreign language pronunciation tutoring: Some issues and a prototype},
	Volume = {2},
	Year = {1999}}

@inproceedings{bunnell2000star,
	Author = {Bunnell, H Timothy and Yarrington, Debra and Polikoff, James B},
	Booktitle = {INTERSPEECH},
	Date-Added = {2014-09-29 18:48:01 +0000},
	Date-Modified = {2014-09-29 18:48:01 +0000},
	Organization = {Citeseer},
	Pages = {85--88},
	Title = {STAR: articulation training for young children.},
	Year = {2000}}

@article{hansen2006computer,
	Author = {Hansen, Thomas K},
	Date-Added = {2014-09-29 18:45:57 +0000},
	Date-Modified = {2014-09-29 18:45:57 +0000},
	Journal = {Current Developments in Technology-Assisted Education},
	Pages = {342--6},
	Publisher = {Citeseer},
	Title = {Computer assisted pronunciation training: The four'K's of feedback},
	Year = {2006}}

@article{engwall2007pronunciation,
	Author = {Engwall, Olov and B{\"a}lter, Olle},
	Date-Added = {2014-09-29 18:45:09 +0000},
	Date-Modified = {2014-09-29 18:45:09 +0000},
	Journal = {Computer Assisted Language Learning},
	Number = {3},
	Pages = {235--262},
	Publisher = {Taylor \& Francis},
	Title = {Pronunciation feedback from real and virtual language teachers},
	Volume = {20},
	Year = {2007}}

@article{nickerson1973teaching,
	Author = {Nickerson, Raymond S and Stevens, Kenneth N},
	Date-Added = {2014-09-29 18:43:32 +0000},
	Date-Modified = {2014-09-29 18:43:32 +0000},
	Journal = {Audio and Electroacoustics, IEEE Transactions on},
	Number = {5},
	Pages = {445--455},
	Publisher = {IEEE},
	Title = {Teaching speech to the deaf: Can a computer help?},
	Volume = {21},
	Year = {1973}}

@article{neri2002pedagogy,
	Author = {Neri, Ambra and Cucchiarini, Catia and Strik, Helmer and Boves, Lou},
	Date-Added = {2014-09-29 18:43:01 +0000},
	Date-Modified = {2014-09-29 18:43:01 +0000},
	Journal = {Computer Assisted Language Learning},
	Number = {5},
	Pages = {441--467},
	Publisher = {Taylor \& Francis},
	Title = {The pedagogy-technology interface in computer assisted pronunciation training},
	Volume = {15},
	Year = {2002}}

@inproceedings{arslan1997frequency,
	Abstract = {In this study, the frequency characteristics of foreign accented speech is investigated. Experiments are conducted to discover the relative significance of different resonant frequencies and frequency bands in terms of their accent discrimination ability. It is shown that second and third formants are more important than other resonant frequencies. A filter bank analysis of accented speech supports this statement, where the 1500-2500 Hz range was shown to be the most significant frequency range in discriminating accented speech. Based on these results, a new frequency scale is proposed in place of the commonly used Mel-scale to extract the cepstrum coefficients from the speech signal. The proposed scale results in better performance for the problems of accent classification and language identification},
	Annote = {- 2nd and 3rd formants are most important 
- MFCC vs ASCC},
	Author = {Arslan, Levent M and Hansen, John HL},
	Booktitle = {Acoustics, Speech, and Signal Processing, 1997. ICASSP-97., 1997 IEEE International Conference on},
	Date-Added = {2014-09-10 18:28:50 +0000},
	Date-Modified = {2014-12-30 10:36:37 +0000},
	Organization = {IEEE},
	Pages = {1123--1126},
	Title = {Frequency characteristics of foreign accented speech},
	Volume = {2},
	Year = {1997},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QD0Fyc2xhbi0xOTk3LnBkZtIXCxgZV05TLmRhdGFPEQGWAAAAAAGWAAIAAAJIRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADO80NASCsAAADbSBgPQXJzbGFuLTE5OTcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANtIGdBO5I8AAAAAAAAAAAABAAIAAAkgAAAAAAAAAAAAAAAAAAAAA2xpdAAAEAAIAADO87PAAAAAEQAIAADQT0b/AAAAAQAcANtIGADbSBIA20d7AAjZvAAI2bsACDaEAAJkZgACAEJIRDpVc2VyczoAZHVkeToAQ1NMVToAUHJvamVjdHM6AHNjb3Jpbmc6AGRvYzoAbGl0OgBBcnNsYW4tMTk5Ny5wZGYADgAgAA8AQQByAHMAbABhAG4ALQAxADkAOQA3AC4AcABkAGYADwAGAAIASABEABIAOFVzZXJzL2R1ZHkvQ1NMVS9Qcm9qZWN0cy9zY29yaW5nL2RvYy9saXQvQXJzbGFuLTE5OTcucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AoAClAK0CRwJJAk4CWQJiAnACdAJ7AoQCiQKWApkCqwKuArMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACtQ==}}

@article{bates2007symbolic,
	Abstract = {A significant source of variation in spontaneous speech is due to intra-speaker pronunciation changes, often realized as small feature changes, e.g., nasalized vowels or affricated stops, rather than full phone transformations. Previous computational modeling of pronun- ciation variation has typically involved transformations from one phone to another, in part because most speech processing systems use phone-based units. Here, a phonetic-feature-based prediction model is presented where phones are represented by a vector of symbolic features that can be on, off, unspecified or unused. Feature interaction is examined using different groupings of possibly dependent features, and a hierarchical grouping with conditional dependencies led to the best results. Feature-based models are shown to be more efficient than phone-based models, in the sense of requiring fewer parameters to predict variation while giving smaller distance and perplexity values when comparing predictions to the hand-labeled reference. A parsimonious model is better suited to incorporating new conditioning factors, and this work investigates high-level information sources, including both text (syntax, discourse) and prosody cues. Experiments show that feature-based models benefit from prosody cues, but not text, and that phone-based models do not benefit from any of the high-level cues explored here.},
	Annote = {- table for feat set for all phonemes
- phone based vs feat based},
	Author = {Bates, Rebecca A and Ostendorf, Mari and Wright, Richard A},
	Date-Added = {2014-09-10 18:27:29 +0000},
	Date-Modified = {2014-12-30 10:36:25 +0000},
	Journal = {Speech Communication},
	Keywords = {Linguistic features; Pronunciation modeling; Conversational speech},
	Number = {2},
	Pages = {83--97},
	Publisher = {Elsevier},
	Title = {Symbolic phonetic features for modeling of pronunciation variation},
	Volume = {49},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV5CYXRlcy0yMDA3LnBkZtIXCxgZV05TLmRhdGFPEQGUAAAAAAGUAAIAAAJIRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADO80NASCsAAADbSBgOQmF0ZXMtMjAwNy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANtIGtBO5I8AAAAAAAAAAAABAAIAAAkgAAAAAAAAAAAAAAAAAAAAA2xpdAAAEAAIAADO87PAAAAAEQAIAADQT0b/AAAAAQAcANtIGADbSBIA20d7AAjZvAAI2bsACDaEAAJkZgACAEFIRDpVc2VyczoAZHVkeToAQ1NMVToAUHJvamVjdHM6AHNjb3Jpbmc6AGRvYzoAbGl0OgBCYXRlcy0yMDA3LnBkZgAADgAeAA4AQgBhAHQAZQBzAC0AMgAwADAANwAuAHAAZABmAA8ABgACAEgARAASADdVc2Vycy9kdWR5L0NTTFUvUHJvamVjdHMvc2NvcmluZy9kb2MvbGl0L0JhdGVzLTIwMDcucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAJ0AogCqAkICRAJJAlQCXQJrAm8CdgJ/AoQCkQKUAqYCqQKuAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArA=}}

@article{cincarek2009automatic,
	Abstract = {This paper describes an approach for automatic scoring of pronunciation quality for non-native speech. It is applicable regardless of the foreign language student's mother tongue. Sentences and words are considered as scoring units. Addition- ally, mispronunciation and phoneme confusion statistics for the target language phoneme set are derived from human annotations and word level scoring results using a Markov chain model of mispronunciation detection. The proposed methods can be employed for building a part of the scoring module of a system for computer assisted pronunciation train- ing (CAPT). Methods from pattern and speech recognition are applied to develop appropriate feature sets for sentence and word level scoring. Besides features well-known from and approved in previous research, e.g. phoneme accuracy, posterior score, duration score and recognition accuracy, new features such as high-level phoneme confidence measures are identi- fied. The proposed method is evaluated with native English speech, non-native English speech from German, French, Jap- anese, Indonesian and Chinese adults and non-native speech from German school children. The speech data are annotated with tags for mispronounced words and sentence level ratings by native English teachers. Experimental results show, that the reliability of automatic sentence level scoring by the system is almost as high as the average human evaluator. Further- more, a good performance for detecting mispronounced words is achieved. In a validation experiment, it could also be verified, that the system gives the highest pronunciation quality scores to 90% of native speakers' utterances. Automatic error diagnosis based on a automatically derived phoneme mispronunciation statistic showed reasonable results for five non-native speaker groups. The statistics can be exploited in order to provide the non-native feedback on mispronounced phonemes.},
	Annote = {- regardless the non native's language
- old feats: phoneme acc, proterior score, duration score recognition acc.
- new feats: high level phoneme confidence measures
- score adjustment
- based on phoneme confusion matrix
- the degree of which a word recognition is trusted is assumed to reflect its quality (using sentence likelihood) 
},
	Author = {Cincarek, Tobias and Gruhn, Rainer and Hacker, Christian and N{\"o}th, Elmar and Nakamura, Satoshi},
	Date-Added = {2014-09-10 18:26:34 +0000},
	Date-Modified = {2014-12-30 10:36:10 +0000},
	Journal = {Computer Speech \& Language},
	Keywords = {Non-native speech; Pronunciation assessment; Sentence scoring; Word scoring; Mispronunciation detection; Phoneme mis- pronunciation statistic},
	Number = {1},
	Pages = {65--88},
	Publisher = {Elsevier},
	Title = {Automatic pronunciation scoring of words and sentences independent from the non-native's first language},
	Volume = {23},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QEUNpbmNhcmVrLTIwMDkucGRm0hcLGBlXTlMuZGF0YU8RAZ4AAAAAAZ4AAgAAAkhEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAM7zQ0BIKwAAANtIGBFDaW5jYXJlay0yMDA5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA20gb0E7kjwAAAAAAAAAAAAEAAgAACSAAAAAAAAAAAAAAAAAAAAADbGl0AAAQAAgAAM7zs8AAAAARAAgAANBPRv8AAAABABwA20gYANtIEgDbR3sACNm8AAjZuwAINoQAAmRmAAIAREhEOlVzZXJzOgBkdWR5OgBDU0xVOgBQcm9qZWN0czoAc2NvcmluZzoAZG9jOgBsaXQ6AENpbmNhcmVrLTIwMDkucGRmAA4AJAARAEMAaQBuAGMAYQByAGUAawAtADIAMAAwADkALgBwAGQAZgAPAAYAAgBIAEQAEgA6VXNlcnMvZHVkeS9DU0xVL1Byb2plY3RzL3Njb3JpbmcvZG9jL2xpdC9DaW5jYXJlay0yMDA5LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKIApwCvAlECUwJYAmMCbAJ6An4ChQKOApMCoAKjArUCuAK9AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAr8=}}

@article{cucchiarini2000different,
	Abstract = {The ultimate aim of the research reported on here is to develop an automatic testing system for Dutch pronunciation. In the experiment described in this paper automatic scores of telephone speech produced by native and non-native speakers of Dutch are compared with speci{\textregistered}c, i.e., temporal and segmental, and global pronunciation ratings assigned by three groups of experts: three phoneticians and two groups of three speech therapists. The goals of this experiment are to determinutee (1) whether speci{\textregistered}c expert ratings of pronunciation quality contribute to our understanding of the relation between human pronunciation scores and machine scores of speech quality, (2) whether di􏰀erent expert groups assign essentially di􏰀erent ratings, and (3) to what extent rater pronunciation scores can be predicted on the basis of automatic scores. The results show that collecting speci{\textregistered}c ratings along with overall ones leads to a better under- standing of the relation between human and automatic pronunciation assessment. Furthermore, after normalization no considerable di􏰀erences are observed between the ratings by the three expert groups. Finally, it appears that the speech quality scores produced by our speech recognizer can predict expert pronunciation ratings with a high degree of accuracy. {\'O} 2000 Published by Elsevier Science B.V.},
	Annote = {- for Dutch pronunciation 
- segmental quality
- similar approach to strik 97'},
	Author = {Cucchiarini, Catia and Strik, Helmer and Boves, Lou},
	Date-Added = {2014-09-10 18:25:31 +0000},
	Date-Modified = {2014-12-30 10:35:59 +0000},
	Journal = {Speech Communication},
	Keywords = {Automatic pronunciation assessment; Expert ratings; Native and non-native pronunciation},
	Number = {2},
	Pages = {109--119},
	Publisher = {Elsevier},
	Title = {Different aspects of expert pronunciation quality ratings and their relation to scores produced by speech recognition algorithms},
	Volume = {30},
	Year = {2000},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFEN1Y2NoaWFyaW5pLTIwMDAucGRm0hcLGBlXTlMuZGF0YU8RAawAAAAAAawAAgAAAkhEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAM7zQ0BIKwAAANtIGBRDdWNjaGlhcmluaS0yMDAwLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA20gc0E7kjwAAAAAAAAAAAAEAAgAACSAAAAAAAAAAAAAAAAAAAAADbGl0AAAQAAgAAM7zs8AAAAARAAgAANBPRv8AAAABABwA20gYANtIEgDbR3sACNm8AAjZuwAINoQAAmRmAAIAR0hEOlVzZXJzOgBkdWR5OgBDU0xVOgBQcm9qZWN0czoAc2NvcmluZzoAZG9jOgBsaXQ6AEN1Y2NoaWFyaW5pLTIwMDAucGRmAAAOACoAFABDAHUAYwBjAGgAaQBhAHIAaQBuAGkALQAyADAAMAAwAC4AcABkAGYADwAGAAIASABEABIAPVVzZXJzL2R1ZHkvQ1NMVS9Qcm9qZWN0cy9zY29yaW5nL2RvYy9saXQvQ3VjY2hpYXJpbmktMjAwMC5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApQCqALICYgJkAmkCdAJ9AosCjwKWAp8CpAKxArQCxgLJAs4AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC0A==}}

@article{franco2010eduspeak,
	Abstract = {SRI International's EduSpeak{\textregistered} system is a software development toolkit that enables developers of interactive language education software to use state-of-the-art speech recognition and pronunciation scoring technology.Automatic pronunciation scoring allows the computer to provide feedback on the overall quality of pronunciation and to point to specific production problems.We review our approach to pronunciation scoring, where our aim is to estimate the grade that a human expert would assign to the pronunciation quality of a paragraph or a phrase. Using databases of nonnative speech and corresponding human ratings at the sentence level, we evaluate different machine scores that can be used as predictor variables to estimate pronunciation quality. For more specific feedback on pronunciation, the EduSpeak toolkit supports a phone-level mispronunciation detection functionality that automatically flags specific phone segments that have been mispronounced. Phone- level information makes it possible to provide the student with feedback about specific pronunciation mistakes.Two approaches to mispronunciation detection were evaluated in a phonetically transcribed database of 130,000 phones uttered in continuous speech sentences by 206 nonnative speakers. Results show that classification error of the best system, for the phones that can be reliably transcribed, is only slightly higher than the average pairwise disagreement between the human transcribers.},
	Annote = {- EduSpeak
- phone level mispronunciation detection
- spectral match, phone duration, word duration, speech rate
- context independent + hmm phone alignment -> log posterior},
	Author = {Franco, Horacio and Bratt, Harry and Rossier, Romain and Gadde, Venkata Rao and Shriberg, Elizabeth and Abrash, Victor and Precoda, Kristin},
	Date-Added = {2014-09-10 18:24:20 +0000},
	Date-Modified = {2014-12-30 10:35:41 +0000},
	Journal = {Language Testing},
	Keywords = {automatic pronunciation scoring, computer aided language learning, mispronunciation detection},
	Number = {3},
	Pages = {401--418},
	Publisher = {SAGE Publications},
	Title = {EduSpeak{\textregistered}: A speech recognition and pronunciation scoring toolkit for computer-aided language learning applications},
	Volume = {27},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QD0ZyYW5jby0yMDEwLnBkZtIXCxgZV05TLmRhdGFPEQGWAAAAAAGWAAIAAAJIRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADO80NASCsAAADbSBgPRnJhbmNvLTIwMTAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANtIHdBO5I8AAAAAAAAAAAABAAIAAAkgAAAAAAAAAAAAAAAAAAAAA2xpdAAAEAAIAADO87PAAAAAEQAIAADQT0b/AAAAAQAcANtIGADbSBIA20d7AAjZvAAI2bsACDaEAAJkZgACAEJIRDpVc2VyczoAZHVkeToAQ1NMVToAUHJvamVjdHM6AHNjb3Jpbmc6AGRvYzoAbGl0OgBGcmFuY28tMjAxMC5wZGYADgAgAA8ARgByAGEAbgBjAG8ALQAyADAAMQAwAC4AcABkAGYADwAGAAIASABEABIAOFVzZXJzL2R1ZHkvQ1NMVS9Qcm9qZWN0cy9zY29yaW5nL2RvYy9saXQvRnJhbmNvLTIwMTAucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AoAClAK0CRwJJAk4CWQJiAnACdAJ7AoQCiQKWApkCqwKuArMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACtQ==}}

@inproceedings{franco1997automatic,
	Abstract = {
This work is part of an effort aimed at developing computer- based systems for language instruction; we address the task of grading the pronunciation quality of the speech of a student of a foreign language. The automatic grading system uses SRI's DecipherTM continuous speech recognition system to generate phonetic segmentations. Based on these segmentations and probabilistic models we produce pronunciation scores for individual or groups of sentences. Scores obtained from expert human listeners are used as the reference to evaluate the different machine scores and to provide targets when training some of the algorithms. In previous work [1] we had found that duration- based scores outperformed HMM log-likelihood-based scores. In this paper we show that we can significantly improve HMM- based scores by using average phone segment posterior probabilities. Correlation between machine and human scores went up from r=0.50 with likelihood-based scores to r=0.88 with posterior-based scores. The new measures also outperformed duration-based scores in their ability to produce reliable scores from only a few sentences.},
	Annote = {- ASR used for segmentations and than probabilistic scores were added to form pronunciation scores
- the new approach outperformed duration based which outperformed hmm based},
	Author = {Franco, Horacio and Neumeyer, Leonardo and Kim, Yoon and Ronen, Orith},
	Booktitle = {Acoustics, Speech, and Signal Processing, 1997. ICASSP-97., 1997 IEEE International Conference on},
	Date-Added = {2014-09-10 17:41:49 +0000},
	Date-Modified = {2014-12-30 10:33:17 +0000},
	Organization = {IEEE},
	Pages = {1471--1474},
	Title = {Automatic pronunciation scoring for language instruction},
	Volume = {2},
	Year = {1997},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QD0ZyYW5jby0xOTk3LnBkZtIXCxgZV05TLmRhdGFPEQGWAAAAAAGWAAIAAAJIRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADO80NASCsAAADbSBgPRnJhbmNvLTE5OTcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANtIHtBO5I8AAAAAAAAAAAABAAIAAAkgAAAAAAAAAAAAAAAAAAAAA2xpdAAAEAAIAADO87PAAAAAEQAIAADQT0b/AAAAAQAcANtIGADbSBIA20d7AAjZvAAI2bsACDaEAAJkZgACAEJIRDpVc2VyczoAZHVkeToAQ1NMVToAUHJvamVjdHM6AHNjb3Jpbmc6AGRvYzoAbGl0OgBGcmFuY28tMTk5Ny5wZGYADgAgAA8ARgByAGEAbgBjAG8ALQAxADkAOQA3AC4AcABkAGYADwAGAAIASABEABIAOFVzZXJzL2R1ZHkvQ1NMVS9Qcm9qZWN0cy9zY29yaW5nL2RvYy9saXQvRnJhbmNvLTE5OTcucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AoAClAK0CRwJJAk4CWQJiAnACdAJ7AoQCiQKWApkCqwKuArMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACtQ==}}

@article{franco2000sri,
	Abstract = {The EduSpeak system is a software development toolkit that enables developers of interactive language education software to use state-of-the-art speech recognition and pronunciation scoring technology. We first report results on the application of adaptation techniques to recognize both native and nonnative speech in a speaker-independent manner. We discuss our pronunciation scoring paradigm and show experimental results in the form of correlations between the pronunciation quality estimators included in the toolkit and grades given by human listeners. We review phone-level pronunciation estimation schemes and describe the phone-level mispronunciation detection functionality that we have incorporated in the toolkit.
TM Finally, we mention some of the EduSpeak toolkit
system features that facilitate the creation and deployment of computer-assisted language learning (CALL) applications.},
	Author = {Franco, Horacio and Abrash, Victor and Precoda, Kristin and Bratt, Harry and Rao, Ramana and Butzberger, John and Rossier, Romain and Cesari, Federico},
	Date-Added = {2014-09-10 17:36:40 +0000},
	Date-Modified = {2014-09-10 17:37:06 +0000},
	Journal = {Proceedings of InSTILL 2000},
	Pages = {123--128},
	Title = {The SRI EduSpeakTM system: Recognition and pronunciation scoring for language learning},
	Year = {2000},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QD0ZyYW5jby0yMDAwLnBkZtIXCxgZV05TLmRhdGFPEQGWAAAAAAGWAAIAAAJIRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADO80NASCsAAADbSBgPRnJhbmNvLTIwMDAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANtIH9BO5I8AAAAAAAAAAAABAAIAAAkgAAAAAAAAAAAAAAAAAAAAA2xpdAAAEAAIAADO87PAAAAAEQAIAADQT0b/AAAAAQAcANtIGADbSBIA20d7AAjZvAAI2bsACDaEAAJkZgACAEJIRDpVc2VyczoAZHVkeToAQ1NMVToAUHJvamVjdHM6AHNjb3Jpbmc6AGRvYzoAbGl0OgBGcmFuY28tMjAwMC5wZGYADgAgAA8ARgByAGEAbgBjAG8ALQAyADAAMAAwAC4AcABkAGYADwAGAAIASABEABIAOFVzZXJzL2R1ZHkvQ1NMVS9Qcm9qZWN0cy9zY29yaW5nL2RvYy9saXQvRnJhbmNvLTIwMDAucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AoAClAK0CRwJJAk4CWQJiAnACdAJ7AoQCiQKWApkCqwKuArMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACtQ==}}

@inproceedings{kim1997automatic,
	Abstract = {The aim of the work described in this paper is to develop methods for automatically assessing the pronunciation quality of specific phone segments uttered by students learning a foreign language. From the phonetic time alignments generated by SRI's DecipherTM HMM-based speech recognition system, we use various probabilistic models to produce pronunciation scores for the phone utterance. We evaluate the performance of the proposed algorithms by measuring how well the machine-produced scores correlate with human judgments on a large database. Of the various algorithms considered, the one based on phone log-posterior-probability produced the highest correlation (rxy = 0.72) with the human ratings, which was comparable with correlations between human raters.},
	Annote = {- ASR, hmm based, aligning
- specific phone segments},
	Author = {Kim, Yoon and Franco, Horacio and Neumeyer, Leonardo},
	Booktitle = {Eurospeech},
	Date-Added = {2014-09-10 17:35:10 +0000},
	Date-Modified = {2014-12-30 10:35:30 +0000},
	Title = {Automatic pronunciation scoring of specific phone segments for language instruction.},
	Year = {1997},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YVxLaW0tMTk5Ny5wZGbSFwsYGVdOUy5kYXRhTxEBjAAAAAABjAACAAACSEQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAzvNDQEgrAAAA20gYDEtpbS0xOTk3LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbSCDQTuSPAAAAAAAAAAAAAQACAAAJIAAAAAAAAAAAAAAAAAAAAANsaXQAABAACAAAzvOzwAAAABEACAAA0E9G/wAAAAEAHADbSBgA20gSANtHewAI2bwACNm7AAg2hAACZGYAAgA/SEQ6VXNlcnM6AGR1ZHk6AENTTFU6AFByb2plY3RzOgBzY29yaW5nOgBkb2M6AGxpdDoAS2ltLTE5OTcucGRmAAAOABoADABLAGkAbQAtADEAOQA5ADcALgBwAGQAZgAPAAYAAgBIAEQAEgA1VXNlcnMvZHVkeS9DU0xVL1Byb2plY3RzL3Njb3JpbmcvZG9jL2xpdC9LaW0tMTk5Ny5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AmwCgAKgCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@article{moustroufas2007automatic,
	Abstract = {In this study we present various techniques to evaluate the pronunciation of students of a foreign language without any knowledge of the uttered text. Previous attempts have shown that it is feasible to evaluate the pronunciation of a non- native speaker by having implicit or explicit knowledge of the uttered text, provided that enough utterances are available. Our approach is to use characteristics of the mother tongue (SOURCE language) of the speaker in the evaluation of his/ her pronunciation. We recorded 20 Greek students speaking English (TARGET language) and evaluated their pronunci- ation using algorithms that include characteristics of the SOURCE language (Greek). We show that the pronunciation scores that are based on both TARGET- and SOURCE-language characteristics have better correlation with the human scores than those based only on characteristics of the TARGET language. As in previous studies, we found that the best- performing algorithms for automatic evaluation of pronunciation are based on speech recognition technology.},
	Annote = {- unknown text
- characteristics of mother tongue speaker to evaluate the speech in English},
	Author = {Moustroufas, N and Digalakis, Vassilios},
	Date-Added = {2014-09-10 17:32:07 +0000},
	Date-Modified = {2014-12-30 10:34:37 +0000},
	Journal = {Computer Speech \& Language},
	Number = {1},
	Pages = {219--230},
	Publisher = {Elsevier},
	Title = {Automatic pronunciation evaluation of foreign speakers using unknown text},
	Volume = {21},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFE1vdXN0cm91ZmFzLTIwMDcucGRm0hcLGBlXTlMuZGF0YU8RAawAAAAAAawAAgAAAkhEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAM7zQ0BIKwAAANtIGBRNb3VzdHJvdWZhcy0yMDA3LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA20gj0E7kjwAAAAAAAAAAAAEAAgAACSAAAAAAAAAAAAAAAAAAAAADbGl0AAAQAAgAAM7zs8AAAAARAAgAANBPRv8AAAABABwA20gYANtIEgDbR3sACNm8AAjZuwAINoQAAmRmAAIAR0hEOlVzZXJzOgBkdWR5OgBDU0xVOgBQcm9qZWN0czoAc2NvcmluZzoAZG9jOgBsaXQ6AE1vdXN0cm91ZmFzLTIwMDcucGRmAAAOACoAFABNAG8AdQBzAHQAcgBvAHUAZgBhAHMALQAyADAAMAA3AC4AcABkAGYADwAGAAIASABEABIAPVVzZXJzL2R1ZHkvQ1NMVS9Qcm9qZWN0cy9zY29yaW5nL2RvYy9saXQvTW91c3Ryb3VmYXMtMjAwNy5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApQCqALICYgJkAmkCdAJ9AosCjwKWAp8CpAKxArQCxgLJAs4AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC0A==}}

@article{neumeyer2000automatic,
	Abstract = {We present a paradigm for the automatic assessment of pronunciation quality by machine. In this scoring paradigm, both native and nonnative speech data is collected and a database of human-expert ratings is created to enable the development of a variety of machine scores. We {\textregistered}rst discuss issues related to the design of speech databases and the reliability of human ratings. We then address pronunciation evaluation as a prediction problem, trying to predict the grade a human expert would assign to a particular skill. Using the speech and the expert-ratings databases, we build statistical models and introduce di􏰀erent machine scores that can be used as predictor variables. We validate these machine scores on the Voice Interactive Language Training System (VILTS) corpus, evaluating the pronunciation of American speakers speaking French and we show that certain machine scores, like the log-posterior and the normalized duration, achieve a correlation with the targeted human grades that is comparable to the human-to-human correlation when a su􏰁cient amount of speech data is available.},
	Annote = {- ASR used for segmentations and than probabilistic scores were added to form pronunciation scores
- the new approach outperformed duration based which outperformed hmm based},
	Author = {Neumeyer, Leonardo and Franco, Horacio and Digalakis, Vassilios and Weintraub, Mitchel},
	Date-Added = {2014-09-10 17:30:51 +0000},
	Date-Modified = {2014-12-30 10:33:39 +0000},
	Journal = {Speech Communication},
	Keywords = {Automatic pronunciation scoring; Speech technology; Hidden Markov models; Speech recognition; Pronunciation quality assessment; Language instruction systems; Computer aided language learning},
	Number = {2},
	Pages = {83--93},
	Publisher = {Elsevier},
	Title = {Automatic scoring of pronunciation quality},
	Volume = {30},
	Year = {2000},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QEU5ldW1leWVyLTIwMDAucGRm0hcLGBlXTlMuZGF0YU8RAZ4AAAAAAZ4AAgAAAkhEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAM7zQ0BIKwAAANtIGBFOZXVtZXllci0yMDAwLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA20gk0E7kjwAAAAAAAAAAAAEAAgAACSAAAAAAAAAAAAAAAAAAAAADbGl0AAAQAAgAAM7zs8AAAAARAAgAANBPRv8AAAABABwA20gYANtIEgDbR3sACNm8AAjZuwAINoQAAmRmAAIAREhEOlVzZXJzOgBkdWR5OgBDU0xVOgBQcm9qZWN0czoAc2NvcmluZzoAZG9jOgBsaXQ6AE5ldW1leWVyLTIwMDAucGRmAA4AJAARAE4AZQB1AG0AZQB5AGUAcgAtADIAMAAwADAALgBwAGQAZgAPAAYAAgBIAEQAEgA6VXNlcnMvZHVkeS9DU0xVL1Byb2plY3RzL3Njb3JpbmcvZG9jL2xpdC9OZXVtZXllci0yMDAwLnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKIApwCvAlECUwJYAmMCbAJ6An4ChQKOApMCoAKjArUCuAK9AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAr8=}}

@inproceedings{neumeyer1996automatic,
	Abstract = {
SRI International is currently involved in the development of a new generation of software systems for automatic scoring of pronunciation as part of the Voice Interactive Language Training System (VILTS) project. This paper describes the goals of the VILTS system, the speech corpus, and the algorithm development. The automatic grading system uses SRI's DecipherTM continuous speech recognition system [1] to generate phonetic segmentations that are used to produce pronunciation scores at the end of each lesson. The scores produced by the system are similar to those of expert human listeners. Unlike previous approaches in which models were built for specific sentences or phrases, we present a new family of algorithms designed to perform well even when knowledge of the exact text to be used is not available.},
	Annote = {- VILTS
- even when the knowledge on the exact text isn't available
- segmentation, hmm, duration(best) and a table to clarify the feats},
	Author = {Neumeyer, Leonardo and Franco, Horacio and Weintraub, Mitchel and Price, Patti},
	Booktitle = {Spoken Language, 1996. ICSLP 96. Proceedings., Fourth International Conference on},
	Date-Added = {2014-09-10 17:29:56 +0000},
	Date-Modified = {2014-12-30 10:33:55 +0000},
	Organization = {IEEE},
	Pages = {1457--1460},
	Title = {Automatic text-independent pronunciation scoring of foreign language student speech},
	Volume = {3},
	Year = {1996},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QEU5ldW1leWVyLTE5OTYucGRm0hcLGBlXTlMuZGF0YU8RAZ4AAAAAAZ4AAgAAAkhEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAM7zQ0BIKwAAANtIGBFOZXVtZXllci0xOTk2LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA20gl0E7kjwAAAAAAAAAAAAEAAgAACSAAAAAAAAAAAAAAAAAAAAADbGl0AAAQAAgAAM7zs8AAAAARAAgAANBPRv8AAAABABwA20gYANtIEgDbR3sACNm8AAjZuwAINoQAAmRmAAIAREhEOlVzZXJzOgBkdWR5OgBDU0xVOgBQcm9qZWN0czoAc2NvcmluZzoAZG9jOgBsaXQ6AE5ldW1leWVyLTE5OTYucGRmAA4AJAARAE4AZQB1AG0AZQB5AGUAcgAtADEAOQA5ADYALgBwAGQAZgAPAAYAAgBIAEQAEgA6VXNlcnMvZHVkeS9DU0xVL1Byb2plY3RzL3Njb3JpbmcvZG9jL2xpdC9OZXVtZXllci0xOTk2LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKIApwCvAlECUwJYAmMCbAJ6An4ChQKOApMCoAKjArUCuAK9AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAr8=}}

@article{russell2000star,
	Abstract = {Between 1990 and 1998, the Speech Research Unit at the Defence Evaluation and Research Agency (DERA), and Hereford and Worcester County Council Education Department, a U.K. local education authority, conducted research into the use of speech recognition technology in an interactive computer-based pronunciation tutor for 5--7 year-old primary school children. The goal of the project was to develop a robust, autonomous system that would enable a child to practice the pronunciation of a given set of words by speaking them to a computer, which provided immediate feedback on whether the pronunciation was acceptable. This paper describes the development of the underlying speech recognition technology, the prototype real-time system which was developed, and the results of pilot trials of the system in a U.K. primary school.},
	Annote = {- `known' spoken word
- in children
- GSM(phoneme caustic models) + word level model
- problem with polysyllabic words
},
	Author = {Russell, Martin and Series, Robert W and Wallace, Julie L and Brown, Catherine and Skilling, Adrian},
	Date-Added = {2014-09-10 17:28:18 +0000},
	Date-Modified = {2014-12-30 10:34:19 +0000},
	Journal = {Computer Speech \& Language},
	Number = {2},
	Pages = {161--175},
	Publisher = {Elsevier},
	Title = {The STAR system: an interactive pronunciation tutor for young children},
	Volume = {14},
	Year = {2000},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QD1J1c3NlbC0yMDAwLnBkZtIXCxgZV05TLmRhdGFPEQGWAAAAAAGWAAIAAAJIRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADO80NASCsAAADbSBgPUnVzc2VsLTIwMDAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANtIJtBO5I8AAAAAAAAAAAABAAIAAAkgAAAAAAAAAAAAAAAAAAAAA2xpdAAAEAAIAADO87PAAAAAEQAIAADQT0b/AAAAAQAcANtIGADbSBIA20d7AAjZvAAI2bsACDaEAAJkZgACAEJIRDpVc2VyczoAZHVkeToAQ1NMVToAUHJvamVjdHM6AHNjb3Jpbmc6AGRvYzoAbGl0OgBSdXNzZWwtMjAwMC5wZGYADgAgAA8AUgB1AHMAcwBlAGwALQAyADAAMAAwAC4AcABkAGYADwAGAAIASABEABIAOFVzZXJzL2R1ZHkvQ1NMVS9Qcm9qZWN0cy9zY29yaW5nL2RvYy9saXQvUnVzc2VsLTIwMDAucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AoAClAK0CRwJJAk4CWQJiAnACdAJ7AoQCiQKWApkCqwKuArMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACtQ==}}

@inproceedings{srikanth2012automatic,
	Abstract = {Feedback on pronunciation is vital for spoken language teaching. Automatic pronuncia- tion evaluation and feedback can help non-native speakers to identify their errors, learn sounds and vocabulary, and improve their pronunciation performance. These evaluations commonly rely on automatic speech recognition, which could be performed using Sphinx trained on a database of native exemplar pronunciation and non-native examples of fre- quent mistakes. Adaptation techniques using target users' enrollment data would yield much better recognition of non-native speech. Pronunciation scores can be calculated for each phoneme, word, and phrase by means of Hidden Markov Model alignment with the phonemes of the expected text. In addition to the basic acoustic alignment scores, we have also adopted the edit distance based criterion to compare the scores of the spoken phrase with those of models for various mispronunciations and alternative correct pronunciations. These scores may be augmented with factors such as expected duration and relative pitch to achieve more accurate agreement with expert phoneticians' average manual subjective pronunciation scores. Such a system is built and documented using the CMU Sphinx3 sys- tem and an Adobe Flash microphone recording, HTML/JavaScript, and rtmplite/Python user interface.},
	Annote = {- using ASR
- native and non native frequent mistakes
- `adaptation' to user's data
- pronunciation scores per phoneme, word, phrase by hmm alignment of the expected text
- edit distance of users 
- pitch
- duration},
	Author = {Srikanth, Ronanki and Salsman, Li Bo2 James},
	Booktitle = {24th International Conference on Computational Linguistics},
	Date-Added = {2014-09-10 16:53:04 +0000},
	Date-Modified = {2014-12-30 10:34:07 +0000},
	Keywords = {Pronunciation Evaluation, Text-independent, forced-alignment, edit- distance neighbor phones decoding, CMUSphinx.},
	Organization = {Citeseer},
	Pages = {61},
	Title = {Automatic Pronunciation Evaluation And Mispronunciation Detection Using CMUSphinx},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QEVNyaWthbnRoLTIwMDgucGRm0hcLGBlXTlMuZGF0YU8RAZ4AAAAAAZ4AAgAAAkhEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAM7zQ0BIKwAAANtIGBFTcmlrYW50aC0yMDA4LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA20go0E7kjwAAAAAAAAAAAAEAAgAACSAAAAAAAAAAAAAAAAAAAAADbGl0AAAQAAgAAM7zs8AAAAARAAgAANBPRv8AAAABABwA20gYANtIEgDbR3sACNm8AAjZuwAINoQAAmRmAAIAREhEOlVzZXJzOgBkdWR5OgBDU0xVOgBQcm9qZWN0czoAc2NvcmluZzoAZG9jOgBsaXQ6AFNyaWthbnRoLTIwMDgucGRmAA4AJAARAFMAcgBpAGsAYQBuAHQAaAAtADIAMAAwADgALgBwAGQAZgAPAAYAAgBIAEQAEgA6VXNlcnMvZHVkeS9DU0xVL1Byb2plY3RzL3Njb3JpbmcvZG9jL2xpdC9TcmlrYW50aC0yMDA4LnBkZgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKIApwCvAlECUwJYAmMCbAJ6An4ChQKOApMCoAKjArUCuAK9AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAr8=}}

@article{wei2009new,
	Abstract = {This paper presents two new ideas for text dependent mispronunciation detection. Firstly, mispronunciation detection is formulated as a classification problem to integrate various predictive features. A Support Vector Machine (SVM) is used as the classifier and the log- likelihood ratios between all the acoustic models and the model corresponding to the given text are employed as features for the classifier. Secondly, Pronunciation Space Models (PSMs) are proposed to enhance the discriminative capability of the acoustic models for pronun- ciation variations. In PSMs, each phone is modeled with several parallel acoustic models to represent pronunciation variations of that phone at different proficiency levels, and an unsupervised method is proposed for the construction of the PSMs. Experiments on a data- base consisting of more than 500,000 Mandarin syllables collected from 1335 Chinese speakers show that the proposed methods can significantly outperform the traditional posterior probability based method. The overall recall rates for the 13 most frequently mispro- nounced phones increase from 17.2%, 7.6% and 0% to 58.3%, 44.3% and 29.5% at three precision levels of 60%, 70% and 80%, respec- tively. The improvement is also demonstrated by a subjective experiment with 30 subjects, in which 53.3% of the subjects think the proposed method is better than the traditional one and 23.3% of them think that the two methods are comparable.},
	Annote = {- text dependent
- svm for classifying text models into acoustic ones
- PSM pronunciation space models - enhance the sum 
- unsupervised method to get PSM
- enables variability for a phoneme
- better than GOP
},
	Author = {Wei, Si and Hu, Guoping and Hu, Yu and Wang, Ren-Hua},
	Date-Added = {2014-09-10 16:51:49 +0000},
	Date-Modified = {2014-12-30 10:32:40 +0000},
	Journal = {Speech Communication},
	Keywords = {Automatic speech recognition; Mispronunciation detection; Support Vector Machine; Pronunciation Space Models},
	Number = {10},
	Pages = {896--905},
	Publisher = {Elsevier},
	Title = {A new method for mispronunciation detection using support vector machine based on pronunciation space models},
	Volume = {51},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YVxXZWktMjAwOS5wZGbSFwsYGVdOUy5kYXRhTxEBjAAAAAABjAACAAACSEQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAzvNDQEgrAAAA20gYDFdlaS0yMDA5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbSCrQTuSPAAAAAAAAAAAAAQACAAAJIAAAAAAAAAAAAAAAAAAAAANsaXQAABAACAAAzvOzwAAAABEACAAA0E9G/wAAAAEAHADbSBgA20gSANtHewAI2bwACNm7AAg2hAACZGYAAgA/SEQ6VXNlcnM6AGR1ZHk6AENTTFU6AFByb2plY3RzOgBzY29yaW5nOgBkb2M6AGxpdDoAV2VpLTIwMDkucGRmAAAOABoADABXAGUAaQAtADIAMAAwADkALgBwAGQAZgAPAAYAAgBIAEQAEgA1VXNlcnMvZHVkeS9DU0xVL1Byb2plY3RzL3Njb3JpbmcvZG9jL2xpdC9XZWktMjAwOS5wZGYAABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AmwCgAKgCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@article{zechner2009automatic,
	Abstract = {This paper presents the first version of the SpeechRaterSM system for automatically scoring non-native spontaneous high-entropy speech in the context of an online practice test for prospective takers of the Test of English as a Foreign Language{\`O} internet-based test (TOEFL{\`O} iBT).
The system consists of a speech recognizer trained on non-native English speech data, a feature computation module, using speech recognizer output to compute a set of mostly fluency based features, and a multiple regression scoring model which predicts a speaking proficiency score for every test item response, using a subset of the features generated by the previous component. Experiments with classification and regression trees (CART) complement those performed with multiple regression. We evaluate the system both on TOE- FL Practice data [TOEFL Practice Online (TPO)] as well as on Field Study data collected before the introduction of the TOEFL iBT.
Features are selected by test development experts based on both their empirical correlations with human scores as well as on their coverage of the concept of communicative competence.
We conclude that while the correlation between machine scores and human scores on TPO (of 0.57) still differs by 0.17 from the inter- human correlation (of 0.74) on complete sets of six items (Pearson r correlation coefficients), the correlation of 0.57 is still high enough to warrant the deployment of the system in a low-stakes practice environment, given its coverage of several important aspects of commu- nicative competence such as fluency, vocabulary diversity, grammar, and pronunciation. Another reason why the deployment of the sys- tem in a low-stakes practice environment is warranted is that this system is an initial version of a long-term research and development program where features related to vocabulary, grammar, and content will be added in a later stage when automatic speech recognition performance improves, which can then be easily achieved without a re-design of the system.
Exact agreement on single TPO items between our system and human scores was 57.8%, essentially at par with inter-human agree- ment of 57.2%.
Our system has been in operational use to score TOEFL Practice Online Speaking tests since the Fall of 2006 and has since scored tens of thousands of tests.},
	Annote = {- ASR trained on non native English
- computes mostly fluency based feats
- multiple regression scoring model - proficiency score
- machine with human score corr of 0.57, inter human score 0.74},
	Author = {Zechner, Klaus and Higgins, Derrick and Xi, Xiaoming and Williamson, David M},
	Date-Added = {2014-09-10 16:40:09 +0000},
	Date-Modified = {2014-12-30 10:31:07 +0000},
	Journal = {Speech Communication},
	Keywords = {Speech scoring; Automatic scoring; Spoken language scoring; Scoring of spontaneous speech; Speaking assessment},
	Number = {10},
	Pages = {883--895},
	Publisher = {Elsevier},
	Title = {Automatic scoring of non-native spontaneous speech in tests of spoken English},
	Volume = {51},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QEFplY2huZXItMjAwOS5wZGbSFwsYGVdOUy5kYXRhTxEBnAAAAAABnAACAAACSEQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAzvNDQEgrAAAA20gYEFplY2huZXItMjAwOS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbSC3QTuSPAAAAAAAAAAAAAQACAAAJIAAAAAAAAAAAAAAAAAAAAANsaXQAABAACAAAzvOzwAAAABEACAAA0E9G/wAAAAEAHADbSBgA20gSANtHewAI2bwACNm7AAg2hAACZGYAAgBDSEQ6VXNlcnM6AGR1ZHk6AENTTFU6AFByb2plY3RzOgBzY29yaW5nOgBkb2M6AGxpdDoAWmVjaG5lci0yMDA5LnBkZgAADgAiABAAWgBlAGMAaABuAGUAcgAtADIAMAAwADkALgBwAGQAZgAPAAYAAgBIAEQAEgA5VXNlcnMvZHVkeS9DU0xVL1Byb2plY3RzL3Njb3JpbmcvZG9jL2xpdC9aZWNobmVyLTIwMDkucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKEApgCuAk4CUAJVAmACaQJ3AnsCggKLApACnQKgArICtQK6AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArw=}}

@article{Strik09,
	Abstract = {One of the biggest challenges in designing computer assisted language learning (CALL) applications that provide automatic feedback on pronunciation errors consists in reliably detecting the pronunciation errors at such a detailed level that the information provided can be useful to learners. In our research we investigate pronunciation errors frequently made by foreigners learning Dutch as a second lan- guage. In the present paper we focus on the velar fricative /x/ and the velar plosive /k/. We compare four types of classifiers that can be used to detect erroneous pronunciations of these phones: two acoustic--phonetic classifiers (one of which employs Linear Discriminant Analysis (LDA)), a classifier based on cepstral coefficients in combination with LDA, and one based on confidence measures (the so- called Goodness Of Pronunciation score). The best results were obtained for the two LDA classifiers which produced accuracy levels of about 85--93%.},
	Annote = {- /x/ vs /k/
- 4 different classifiers; LDA APF, LDA MFCC, GOP and APF
- both LDA performed better },
	Author = {H. Strik and K. Truong and F. de Wet and C. Cucchiarini},
	Date-Added = {2014-01-07 16:47:35 +0000},
	Date-Modified = {2014-12-30 10:32:57 +0000},
	Journal = {Speech Communication},
	Pages = {845--852},
	Title = {Comparing different approaches for automatic pronunciation error detection},
	Volume = {51},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV5TdHJpay0yMDA5LnBkZtIXCxgZV05TLmRhdGFPEQGUAAAAAAGUAAIAAAJIRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADO80NASCsAAADbSBgOU3RyaWstMjAwOS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANtIKdBO5I8AAAAAAAAAAAABAAIAAAkgAAAAAAAAAAAAAAAAAAAAA2xpdAAAEAAIAADO87PAAAAAEQAIAADQT0b/AAAAAQAcANtIGADbSBIA20d7AAjZvAAI2bsACDaEAAJkZgACAEFIRDpVc2VyczoAZHVkeToAQ1NMVToAUHJvamVjdHM6AHNjb3Jpbmc6AGRvYzoAbGl0OgBTdHJpay0yMDA5LnBkZgAADgAeAA4AUwB0AHIAaQBrAC0AMgAwADAAOQAuAHAAZABmAA8ABgACAEgARAASADdVc2Vycy9kdWR5L0NTTFUvUHJvamVjdHMvc2NvcmluZy9kb2MvbGl0L1N0cmlrLTIwMDkucGRmAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAJ0AogCqAkICRAJJAlQCXQJrAm8CdgJ/AoQCkQKUAqYCqQKuAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArA=}}

@article{Witt00,
	Abstract = {This paper investigates a method of automatic pronunciation scoring for use in computer-assisted language learning (CALL) systems. The method utilises a likelihood-based `Goodness of Pronunciation' (GOP) measure which is ex- tended to include individual thresholds for each phone based on both averaged native con{\textregistered}dence scores and on re- jection statistics provided by human judges. Further improvements are obtained by incorporating models of the subject{\~O}s native language and by augmenting the recognition networks to include expected pronunciation errors. The various GOP measures are assessed using a specially recorded database of non-native speakers which has been an- notated to mark phone-level pronunciation errors. Since pronunciation assessment is highly subjective, a set of four performance measures has been designed, each of them measuring di􏰅erent aspects of how well computer-derived phone-level scores agree with human scores. These performance measures are used to cross-validate the reference annotations and to assess the basic GOP algorithm and its re{\textregistered}nements. The experimental results suggest that a like- lihood-based pronunciation scoring metric can achieve usable performance, especially after applying the various en- hancements. {\'O} 2000 Elsevier Science B.V. All rights reserved.},
	Annote = {- pronunciation scoring for use in assisted language learning syms.
- individual threshold for each phone based on (a) average native confidence (b) rejection    stats(human)
- augmenting recognition network (trained on native) to include expected pronunciation error
- test on non-native 
- 4 performance measures to test computer results against human: strictness, agreement, cross validation and overall phone corr. },
	Author = {S. M. Witt and S. J. Young},
	Date-Added = {2014-01-07 02:42:03 +0000},
	Date-Modified = {2014-12-30 10:31:39 +0000},
	Journal = {Speech Communication},
	Number = {2},
	Pages = {95--108},
	Title = {Phone-level pronunciation scoring and assessment for interactive language learning},
	Volume = {30},
	Year = {2000},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV1XaXR0LTIwMDAucGRm0hcLGBlXTlMuZGF0YU8RAY4AAAAAAY4AAgAAAkhEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAM7zQ0BIKwAAANtIGA1XaXR0LTIwMDAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA20gs0E7kjwAAAAAAAAAAAAEAAgAACSAAAAAAAAAAAAAAAAAAAAADbGl0AAAQAAgAAM7zs8AAAAARAAgAANBPRv8AAAABABwA20gYANtIEgDbR3sACNm8AAjZuwAINoQAAmRmAAIAQEhEOlVzZXJzOgBkdWR5OgBDU0xVOgBQcm9qZWN0czoAc2NvcmluZzoAZG9jOgBsaXQ6AFdpdHQtMjAwMC5wZGYADgAcAA0AVwBpAHQAdAAtADIAMAAwADAALgBwAGQAZgAPAAYAAgBIAEQAEgA2VXNlcnMvZHVkeS9DU0xVL1Byb2plY3RzL3Njb3JpbmcvZG9jL2xpdC9XaXR0LTIwMDAucGRmABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AnAChAKkCOwI9AkICTQJWAmQCaAJvAngCfQKKAo0CnwKiAqcAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACqQ==}}
