#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{spconf}


\ninept

\name{Shiran Dudy and Kyle Gorman}
\address{Center for Spoken Language Understanding, Oregon Health \& Science University\\
Portland, OR, USA\\
{\small \tt dudy@ohsu.edu}}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format pdf4
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 10
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type numerical
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Textual Prediction of Prosodic Prominence in Spontaneous Speech with Sequence
 Classifiers
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Confirmation Number: 1309 Submission Passcode: 1309X-C3A3G6P3E8
\end_layout

\end_inset


\end_layout

\begin_layout Abstract
Speakers produce words with differing degrees of prosodic prominence, as
 do naturalistic text-to-speech systems.
 Prominence also marks contrasts in information structure.
 We describe models for predicting word prominence using textual features
 (such as part of speech).
 We employ sequence classification techniques so as to encode the tendency
 for prominent and non-prominent words to alternate.
 In experiments with the spontaneous speech from the Switchboard database,
 we show that these models produce a significant improvement in classification
 above the baseline.
 Our results suggest that word-level prominences can be accurately inferred
 from relatively shallow textual features.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
definition
\end_layout

\end_inset

Prominence of a syntactic unit in a sentence intends to focus the listener's
 attention to a new concept presented by the speaker
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand citep
key "bolinger1986intonation"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citet
key "cole2014listening"

\end_inset


\begin_inset space ~
\end_inset

showed that the emphasized words in a sentence shape the meaning of the
 sentence in an audio-listening perceptual test of non-expert, native speakers.
 It was also proven that incorporating prosodic cues to an utterance, in
 comparison to both arbitrary emphasis of words and monotonic speech, supports
 language acquisition
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand citep
key "morgan1987structural"

\end_inset

.
 Moreover, apart from conveying messages in an intelligible form, sentences
 lacking prominence were observed in children with autism by
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand citet
key "shriberg2001speech"

\end_inset

.
 In her research, their speech was described monotonic and 'machine like'.
 In other words, prominence contributes to a natural and expressive manner
 of speech.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
TTS+example
\end_layout

\end_inset


\end_layout

\begin_layout Standard
While humans naturally apply prominence, Text to Speech (TTS) systems still
 aim at producing synthesized speech that incorporates prominence
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand citep
key "cooke2013evaluating"

\end_inset

.
 There are two main reasons for which prominence can leverage performance
 in TTS systems.
 First, to convey an intelligible message that clarifies the meaning of
 a sentence.
 Second, to potentially make speech more natural through imitating humans'
 prominence assignments.
 The significance of prominence is illustrated in the following examples:
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
That's what 
\begin_inset Formula $\text{she}^{<}$
\end_inset

 said
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
That's 
\begin_inset Formula $\text{what}^{<}$
\end_inset

 she said
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
this is the source for stress symbolic icon:
\end_layout

\begin_layout Plain Layout
https://haharoni.wordpress.com/2011/10/11/hatama-02/
\end_layout

\end_inset

Monotonic speech, that contains no prominence, would sound not natural and
 make the hearer uncertain of the purpose of the utterance.
 However, when 'she' is emphasized, in the first example, it is assumed
 that the focus is on her and the information coming next would involve
 additional details to support that fact.
 The same goes with 'what' , given in the second example, only that this
 time the expected details would be on what is being said.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
properties
\end_layout

\end_inset

Where can we find evidence of prominence? Prominence of a word is determined
 by three parameters that are expressed in sound: a local maxima or minima
 of the fundamental frequency contour, longer duration of the emphasized
 unit, and a high energy region of speech
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand citep
key "rosenberg2006correlation"

\end_inset

.
 More interestingly, in this work we hypothesize that linguistic features
 contribute to prominence.
 For example, since content words tend to introduce new information, they
 are likely to be accented more often than function words.
 Another example is the presence of contrast in a sentence.
 It is assumed that presenting a clause that undermines a former idea is
 expected to be emphasized in order to point out the contrasting information.
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Another example that influences accent is the presence of a phrase in a
 sentence.
 A phrase is a sequence of accented words within a sentence.
 Within the phrase there will be another dimension of accentuation in the
 form of a word or syllable.
 Another noticeable trend is that the words surrounding a prominent word
 may not, under most circumstances, be prominent
\end_layout

\end_inset

According to
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand citet
key "kimballavoidance"

\end_inset

 non experts native speakers are not capable of perceiving clashes resulted
 by adjacent prominent words and adjust their hearing to perceive a modified
 sentence that detaches and avoids adjacency.
 This finding might also suggest that sentence production involves scattering
 prominence to non-prominent environments by avoiding accenting two or more
 units in a row.
\end_layout

\begin_layout Standard
Therefore, our goal in this research is to develop a model that better predicts
 the prominence in a sentence by examining several different sequence classifier
s that use contextual information.
 We use linguistic features of annotated spontaneous speech, which is known
 to be less predictive than read speech.
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
[since there are phenomena of shortend words so stress and accents has to
 accommodate with irregularities]
\end_layout

\end_inset

We show that our model is significantly better than the baseline.
 
\end_layout

\begin_layout Standard
In the following sections we describe prior work in Section 2, methods to
 build our classifiers in Section 3, performance evaluation in Section 4,
 and conclusions in Section 5.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Contributions
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
define prominence Cole
\end_layout

\begin_layout Plain Layout
perceptual cues 
\end_layout

\begin_layout Plain Layout
what things that humans hear cause them feel it is prominent
\end_layout

\begin_layout Plain Layout
duration pitch intensity
\end_layout

\begin_layout Plain Layout
information structure - define prominece definitaion 
\end_layout

\begin_layout Plain Layout
why for human why for tts 
\end_layout

\begin_layout Plain Layout
pitch accent Juila hirshcberg
\end_layout

\begin_layout Plain Layout
PROBLEM
\end_layout

\begin_layout Plain Layout
naturalness tts
\end_layout

\begin_layout Plain Layout
poour prominence - 
\end_layout

\begin_layout Plain Layout
natural yet intelligble
\end_layout

\begin_layout Plain Layout
prior work textual 
\end_layout

\begin_layout Plain Layout
intuition lapse 
\end_layout

\begin_layout Plain Layout
clash
\end_layout

\begin_layout Plain Layout
=>sequence clas.
 
\end_layout

\begin_layout Plain Layout
spontaious speech
\end_layout

\end_inset


\end_layout

\begin_layout Section
Prior Work
\end_layout

\begin_layout Standard
The prior work in the field of predicting prominence in a sentence is divided
 to two schools of thought: the research that involves acoustics with or
 without linguistic features and the research that is focused only on linguistic
 features.
 We will review both and point out some interesting methods that were developed.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citet
key "rosenberg2009detecting"

\end_inset


\begin_inset space ~
\end_inset

explored which domain of acoustic analysis predicts most accurately pitch
 accents and concluded that the word level reaches the highest accuracy
 of 84.2% on read speech.
 In another study 
\begin_inset CommandInset citation
LatexCommand citep
key "rangarajan2007exploiting"

\end_inset

 applying Maximum Entropy approach on read speech, using Boston University
 Radio News Corpus, scored 86.0% accuracy.
 
\begin_inset CommandInset citation
LatexCommand citet
key "mehrabani2013unsupervised"

\end_inset


\begin_inset space ~
\end_inset

used unsupervised learning to find several clusters to represent prominence
 level found in speech and then modeled the different clusters' relationship
 with linguistic features to predict prominence from a text.
 A German-language study that incorporated knowledge only from acoustics,
 used features like nucleus duration, spectral emphasis, pitch movements,
 and intensity to show correlation between perceptual tests to their predicted
 prominence
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand citep
key "tamburini2007automatic"

\end_inset

.
\end_layout

\begin_layout Standard
In linguistic studies the researchers' focus is on utilizing the syntactic
 information.
 
\begin_inset CommandInset citation
LatexCommand citet
key "windmann2011prominence"

\end_inset


\begin_inset space ~
\end_inset

developed a rule-based voting system based on features such as part of speech
 tags, and dictionary based stress assignments, to determine the prominence
 assignment.
 Another study 
\begin_inset CommandInset citation
LatexCommand citep
key "brenier2006non"

\end_inset

 suggested that using features such as the frequency of a word, the type
 of a noun, and accent ratio eventually results in a 77% in accuracy on
 spontaneous speech.
 Using features found in Switchboard spontaneous corpus such as contrast
 led to 76.58% in accuracy
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand citep
key "nenkova2007memorize"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Not convincing enough
\end_layout

\end_inset

We would like to offer a better linguistic-based solution to predict prominence
 on spontaneous speech.
 Next, we'll present our methods and set of features we chose to use.
\end_layout

\begin_layout Section
Methods
\end_layout

\begin_layout Subsection
Data
\end_layout

\begin_layout Standard
We used 'Switchboard in NXT' database 
\begin_inset CommandInset citation
LatexCommand citep
key "godfrey1992switchboard"

\end_inset

 on annotated spontaneous speech.
 We used 40,647 tokens that constructed 6,425 sentences (or sequences).
 The database offers various features added from Penn Treebank and MS-State
 Transcript projects.
 The features we used were: 
\end_layout

\begin_layout Itemize

\series bold
Terminals
\series default
 containing the orthographic transcription along with its corresponding
 part of speech.
\end_layout

\begin_layout Itemize

\series bold
DialAct
\series default
 containing the dialogue act description such as a statement and a question.
\end_layout

\begin_layout Itemize

\series bold
Kontrast 
\series default
containing the level of kontrast such as word, phrase and whether its contrastiv
e.
\end_layout

\begin_layout Itemize

\series bold
Disfluency
\series default
 containing the places that the speaker hesitates.
 We used only the repair units.
\end_layout

\begin_layout Itemize

\series bold
Phonewords 
\series default
containing similar information like terminals (both eventually were merged).
\end_layout

\begin_layout Itemize

\series bold
Phrases 
\series default
containing groups of words that were assigned with a different prosody such
 as minor and major.
 
\end_layout

\begin_layout Itemize

\series bold
Accent 
\series default
containing the information on level of prominence assigned to each token:
 'full', 'weak', and 'none'.
\end_layout

\begin_layout Subsection
Features
\end_layout

\begin_layout Standard
We extracted information from Switchboard and added additional features
 that may further tell about the accent which is the target prediction in
 our experiment.
 
\end_layout

\begin_layout Standard
In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:feature-set"

\end_inset

, the blue represents the feature set referred to as 
\begin_inset Formula $X$
\end_inset

.
 Our feature set was: the word, its part of speech, its collapsed part of
 speech, whether it is a function and a negation word, the token's syllable's
 vowel-group by order, the token's nucleus, nucleus kind, kontrast level,
 kontrast type, whether it is a phrase, phrase kind, and the description
 of the discourse.
 In pink, there is the true target 
\begin_inset Formula $y$
\end_inset

 describing the accent.
 In this case, only 'pretty' is assigned with 'full' type of accent and
 all the rest are assigned with 'none' accent.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename featset1.pdf
	lyxscale 40
	scale 35

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:feature-set"

\end_inset

sequence of feature set and its corresponding target accents 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Models
\end_layout

\begin_layout Standard
We used sequence classifying models to exploit the internal relationships
 found in adjacent observations and consider the problem in its context.
 Models 1-3 were based on Average Perceptron approach 
\begin_inset CommandInset citation
LatexCommand citep
key "collins2002discriminative"

\end_inset

 applying Hidden Markov Models assumptions to these models.
 For models 4, 6 we used a 'PocketCRF' toolkit'
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://pocket-crf-1.sourceforge.net/
\end_layout

\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Enumerate
Local Search (L) -- we employed three models: zero order, first order, and
 second order.
 Zeroth orders's input contained feature set in time 
\begin_inset Formula $t$
\end_inset

: 
\begin_inset Formula $X(t)$
\end_inset

.
 First order's was 
\begin_inset Formula $X(t)$
\end_inset

 and 
\begin_inset Formula $X(t-1)$
\end_inset

.
 Second order's was 
\begin_inset Formula $X(t)$
\end_inset

, 
\begin_inset Formula $X(t-1)$
\end_inset

, and 
\begin_inset Formula $X(t+1)$
\end_inset

.
\end_layout

\begin_layout Enumerate
Greedy Search (G) -- we employed an input that contained feature set of
 time 
\begin_inset Formula $t$
\end_inset

 together with last prediction for time 
\begin_inset Formula $t-1$
\end_inset

.
 The input was 
\begin_inset Formula $X(t)$
\end_inset

, 
\begin_inset Formula $\hat{y}(t-1)$
\end_inset

 and transition features.
 
\end_layout

\begin_layout Enumerate
Viterbi Search (V) -- we employed First order Viterbi algorithm 
\begin_inset CommandInset citation
LatexCommand citep
key "viterbi1967error"

\end_inset

.
\end_layout

\begin_layout Enumerate
Conditional Random Fields Search (CRF) -- we employed an input that contained
 
\begin_inset Formula $X(t)$
\end_inset

, 
\begin_inset Formula $X(t-1)$
\end_inset

, and 
\begin_inset Formula $X(t+1)$
\end_inset


\begin_inset CommandInset citation
LatexCommand citep
key "lafferty2001conditional"

\end_inset

.
 
\end_layout

\begin_layout Enumerate
Max Margin Markov Networks Search (M3N) -- we employed an input that contained
 
\begin_inset Formula $X(t)$
\end_inset

, 
\begin_inset Formula $X(t-1)$
\end_inset

, and 
\begin_inset Formula $X(t+1)$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand citep
key "roller2004max"

\end_inset

.
 
\end_layout

\begin_layout Enumerate
Baseline -- our baseline was set by guessing the most probable target found
 in the database.
 In our experiment the guess was 'none' accent type.
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Standard
We performed a 10 fold cross-validation test and averaged all accuracy results
 for token and sentence level tests.
\end_layout

\begin_layout Subsection
Token Level Accuracy
\end_layout

\begin_layout Standard
The models were tested for their token accuracy.
 Accuracy was measured by counting the correct classifications over all
 classifications.
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:token accuracy"

\end_inset

 describes the accuracy of the classifications using the models.
 We noticed that all Local Searches performed the best, then, the Viterbi
 and the Greedy which were close to each other and lasts are the CRF as
 well as the M3N, yet still seemed to be different than the baseline.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="9" columns="2">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="right" valignment="top" width="0pt">
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Accuracy[%]
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L 0th
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
79.1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L 1st
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
79.2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L 2nd
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
79.0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
G
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
77.2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
V
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
77.5
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CRF
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
74.7
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
M3N
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
72.3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Baseline
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
69.9
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:token accuracy"

\end_inset

 Classification Accuracy 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
All models performed better than the basline but we needed to understand
 how significant results were.
 Next, we applied Wilson Confidence Interval 
\begin_inset CommandInset citation
LatexCommand citep
key "wallis2013binomial"

\end_inset

 to have a better idea of whether the models are different or that their
 confidence interval overlap and they were driven from the same population.
 Looking at Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:wilson"

\end_inset

, we noticed that all models seem to differ than the basline since none
 overlap with it.
 We also saw that Local Searches demostrates overlap within group but does
 not overlap with Greedy and Viterbi.
 Greedy and Viterbi overlap but do not overlap with CRF.
 For the same reason, CRF and M3N do not seem to represent a similar population
 as well.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename wilson.pdf
	lyxscale 40
	scale 40

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:wilson"

\end_inset

Wilson Score 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Finally, we performed a Mcneamar 
\begin_inset CommandInset citation
LatexCommand citep
key "fagerland2013mcnemar"

\end_inset

 test to determine the significance of our results.
 Mcneamar test compares two models in terms of how many true positive and
 true negtive were predicted in each model -- this determines the differences
 in model populations.
 
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="3">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="right" valignment="top" width="0pt">
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model B
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
p-value
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
M3N
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Baseline
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.82e-22
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CRF
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
M3N
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4.74e-197
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
G
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CRF
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9.04e-137
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
V
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
G
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L 2nd
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
V
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.2e-38
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L 0th
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L 2nd
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.05
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L 1st
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L 0th
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.18
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:McNeamar"

\end_inset

 Mcneamar Significance Test 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:McNeamar"

\end_inset

, we sorted the groups in increasing accuracy order and showed a pairwise
 comparison between two adjacent models.
 P-values that were below 0.01 were demonstrated two significantly different
 models.
 We can see that M3N, CRF, Viterbi and Greedy together, and all Local Searches
 form four significantly different populations than the baseline.
 The Best model is the Local Search.
\end_layout

\begin_layout Standard
Our initial intuition of applying Averaged Perceptron approach was that
 it will perform better since during training the model is penalized proportiona
ly when the prediction is not like the true target.
 This regularization proved to be helpful.
 However, we expected that Viterbi and Greedy search would outperform Local
 Search since the former incorporate knowledge of the past prediction 
\begin_inset Formula $\hat{y}(t-1)$
\end_inset

 and it thought to be an important feature for deciding whether the current
 feature should be prominent.
 The possible explanation for that might derive from the transition features
 that were added to the input in Viterbi and Greedy and damaged the learning.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
M3N CRF
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Sentence Level Accuracy 
\end_layout

\begin_layout Standard
We know that it takes one misclassification of prominence to understand
 the sentence entirely differently as seen in the examples given in the
 Introduction Section.
 Therefore, we adopted a more rigid approach that measures how many fully
 correctly classified sentences the models predicted.
 This could help understand how many times we are confident that the message
 was conveyed the way the speaker intended.
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:sentence accuracy"

\end_inset

 describes the accuracy results for this experiment:
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="9" columns="2">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="right" valignment="top" width="0pt">
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Accuracy[%]
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L 0th
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
48.4
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L 1st
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
48.9
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L 2nd
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
48.9
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
G
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
48.9
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
V
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
48.9
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CRF
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
34.8
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
M3N
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
32.8
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Baseline
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
42.0
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:sentence accuracy"

\end_inset

 Classification Accuracy 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
To finalize these results we used a Binomial Test to measure significance.We
 compared accuracies of baseline with all models that were above baseline.
 We conducted a Binomial Test that compares between two models' accuracy
 result and found that the Local Search 0 order is significantly different
 than the baseline with p-value of 5.19e-75.
 The p-value for Viterbi, Greedy, Local Search 1 and 2 with the baseline
 is 2.22e-84.
 Our models, therefore, were able to send a more correct messages than using
 baseline predictions.
 
\end_layout

\begin_layout Standard
Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:sentence accuracy"

\end_inset

 shows that the Local, Greedy and Viterbi Search share similar pattern learning
 that is expressed in sentence accuracy.
 We can also infer that though the Local Search has a better accuracy result
 on a token level it is not expressed in terms of sentence accuracy.
 
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
In this research we showed that employing linguistic features extracted
 from spontaneous speech to create a prominence predicting model were significan
tly different than baseline guessing.
 This knowledge can be incorporated to a TTS system to improve intelligibly
 and to make it more natural.
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "prom"
options "plainnat"

\end_inset


\end_layout

\end_body
\end_document
